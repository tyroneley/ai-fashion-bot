from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pathlib import Path
import shutil
import uuid
from typing import List

from .config import UPLOADS_DIR, GENERATED_DIR, MEDIA_DIR
from .models import GenerateDesignResponse
from .generator import build_gemini_instruction, call_gemini_for_prompt, refine_for_image_model
from .tones import TONES, KANSEI_WORDS

# Optional import - only load when needed to avoid PyTorch DLL issues
try:
    from .image_generator import generate_fashion_design
    IMAGE_GENERATION_AVAILABLE = True
except Exception as e:
    print(f"Warning: Image generation disabled. Error loading dependencies: {e}")
    IMAGE_GENERATION_AVAILABLE = False
    generate_fashion_design = None

app = FastAPI(
    title="Fashion Emotion Design API",
    description="Backend for emotion-aware CAD-style fashion design generation.",
    version="0.1.0",
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Serve media files
app.mount("/media", StaticFiles(directory=str(MEDIA_DIR)), name="media")


@app.post("/api/generate-design", response_model=GenerateDesignResponse)
async def generate_design(
    image: UploadFile = File(...),
    kansei_text: str = Form(...),
    style_profile: str | None = Form(None),
    tones: List[str] = Form(default=[]),
    kansei_words: List[str] = Form(default=[]),
):
    """
    Main endpoint: receives sketch + kansei text + optional tones/Kansei words.
    
    - Saves the uploaded sketch
    - Calls Gemini to generate a detailed prompt based on selected tones/Kansei
    - Returns generated_image_url and the LLM prompt
    """

    # 1. Save the uploaded sketch
    sketch_id = uuid.uuid4().hex
    original_ext = Path(image.filename).suffix or ".png"
    sketch_filename = f"sketch_{sketch_id}{original_ext}"
    sketch_path = UPLOADS_DIR / sketch_filename

    with sketch_path.open("wb") as buffer:
        shutil.copyfileobj(image.file, buffer)

    # 2. Call Gemini to generate prompt
    try:
        instruction = build_gemini_instruction(tones, kansei_words)
        gemini_prompt = call_gemini_for_prompt(instruction)
        llm_prompt = refine_for_image_model(gemini_prompt)
    except Exception as e:
        # Handle various API errors
        error_msg = str(e)
        if "403" in error_msg or "PERMISSION_DENIED" in error_msg:
            if "leaked" in error_msg.lower():
                llm_prompt = "Gemini API Error: Your API key has been reported as leaked and disabled. Please generate a new API key from https://aistudio.google.com/apikey and update your .env file."
            else:
                llm_prompt = "Gemini API Error: Permission denied. Please check your API key has the correct permissions."
        elif "API key" in error_msg or "GEMINI_API_KEY" in error_msg:
            llm_prompt = "Gemini API Error: API key not configured. Please set GEMINI_API_KEY in your .env file."
        else:
            llm_prompt = f"Gemini API Error: {error_msg}"
        print(f"Gemini error: {error_msg}")

    # 3. Generate image using Stable Diffusion + ControlNet with sketch + prompt
    generated_filename = f"generated_{sketch_id}.png"
    generated_path = GENERATED_DIR / generated_filename
    
    if IMAGE_GENERATION_AVAILABLE:
        try:
            generate_fashion_design(
                sketch_path=sketch_path,
                prompt=llm_prompt,
                output_path=generated_path,
                num_inference_steps=20,
                guidance_scale=7.5,
                controlnet_conditioning_scale=1.0,
            )
        except Exception as e:
            # Fallback: copy sketch if generation fails
            print(f"Image generation failed: {e}")
            shutil.copyfile(sketch_path, generated_path)
    else:
        # Image generation not available, just copy the sketch
        print("Image generation unavailable - returning original sketch")
        shutil.copyfile(sketch_path, generated_path)

    # 4. Build URL for frontend
    generated_image_url = f"/media/generated/{generated_filename}"

    notes = (
        "Generated using Stable Diffusion v1.5 + ControlNet with the Gemini-crafted prompt "
        "conditioned on your CAD sketch."
    )

    return GenerateDesignResponse(
        status="ok",
        generated_image_url=generated_image_url,
        llm_prompt=llm_prompt,
        notes=notes,
    )


@app.get("/api/tones")
async def get_tones():
    """Return available tones and Kansei words for frontend dropdown."""
    return {"tones": TONES, "kansei_words": KANSEI_WORDS}


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy"}


# Mount frontend static files LAST so API routes take precedence
PROJECT_ROOT = Path(__file__).resolve().parents[2]
FRONTEND_DIR = PROJECT_ROOT / "frontend"
if FRONTEND_DIR.exists():
    # Mount frontend at root so index.html is available at '/index.html' and '/'
    app.mount("/", StaticFiles(directory=str(FRONTEND_DIR), html=True), name="frontend")
else:
    # If the frontend folder is missing, leave API-only behavior and log a message
    print(f"Frontend directory not found at {FRONTEND_DIR}; serving API only.")